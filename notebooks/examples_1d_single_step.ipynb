{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce, partial\n",
    "from timeit import default_timer\n",
    "\n",
    "from src.utils.utils import *\n",
    "from src.models.base import FNO1d\n",
    "from src.models.single_step import BOON_FNO1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 500\n",
    "ntest = 100\n",
    "\n",
    "sub = 1 #subsampling rate\n",
    "h = 500 // sub #total grid size divided by the subsampling rate\n",
    "\n",
    "s = h\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 500\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 16\n",
    "width = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# read data\n",
    "################################################################\n",
    "\n",
    "# LOAD YOUR DATA HERE consists of pairs (a,u) with randomly generated initial conditions or PDE parameters a\n",
    "# and solution u\n",
    "rw_ = loadmat('Data/1D/Burgers Dirichlet/burgers_Dirichlet_1D_data_nu_0_point_1.mat')\n",
    "\n",
    "x_data = rw_['a'].astype(np.float32) # shape (num_random_simulations, number_grid_points)\n",
    "y_data = rw_['u'].astype(np.float32) # shape (num_random_simulations, number_grid_points)\n",
    "\n",
    "x_data = torch.from_numpy(x_data)\n",
    "y_data = torch.from_numpy(y_data)\n",
    "\n",
    "x_train = x_data[:ntrain,:]\n",
    "y_train = y_data[:ntrain,:]\n",
    "x_test = x_data[-ntest:,:]\n",
    "y_test = y_data[-ntest:,:]\n",
    "\n",
    "x_train = x_train.unsqueeze(-1)\n",
    "x_test = x_test.unsqueeze(-1)\n",
    "\n",
    "left_bdry_train = y_train[:,0].unsqueeze(-1)\n",
    "right_bdry_train = y_train[:,-1].unsqueeze(-1)\n",
    "\n",
    "left_bdry_test = y_test[:,0].unsqueeze(-1)\n",
    "right_bdry_test = y_test[:,-1].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train, left_bdry_train, right_bdry_train), \n",
    "                                            batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test, left_bdry_test, right_bdry_test), \n",
    "                                            batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_no = FNO1d(modes, width)\n",
    "model = BOON_FNO1d(width, \n",
    "                    base_no,\n",
    "                    bdy_type='dirichlet').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for batch in train_loader:\n",
    "        x, y, left, right = batch\n",
    "        x, y, left, right = x.to(device), y.to(device), left.to(device), right.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, \n",
    "                    bdy_left={'val':left}, \n",
    "                    bdy_right={'val':right}\n",
    "                   )\n",
    "\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward() # use the l2 relative loss\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += l2.item()\n",
    "        \n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y, left, right = batch\n",
    "            x, y, left, right = x.to(device), y.to(device), left.to(device), right.to(device)\n",
    "\n",
    "            out = model(x, \n",
    "                        bdy_left={'val':left}, \n",
    "                        bdy_right={'val':right}\n",
    "                       )\n",
    "\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1,  train_l2, test_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neumann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#  configurations\n",
    "################################################################\n",
    "ntrain = 500\n",
    "ntest = 100\n",
    "\n",
    "sub = 1 #subsampling rate\n",
    "h =500 // sub #total grid size divided by the subsampling rate\n",
    "\n",
    "s = h\n",
    "N = h\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 500\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 16\n",
    "width = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# read data\n",
    "################################################################\n",
    "# LOAD YOUR DATA HERE consists of pairs (a,u) with randomly generated initial conditions or PDE parameters a\n",
    "# and solution u\n",
    "rw_ = loadmat('Data/1D/Heat Neumann/heat_Neumann_1D.mat')\n",
    "\n",
    "x_data = rw_['a'].astype(np.float32) # shape (num_random_simulations, number_grid_points)\n",
    "y_data = rw_['u'].astype(np.float32) # shape (num_random_simulations, number_grid_points)\n",
    "\n",
    "x_data = torch.from_numpy(x_data)\n",
    "y_data = torch.from_numpy(y_data)\n",
    "\n",
    "x_train = x_data[:ntrain,::sub]\n",
    "y_train = y_data[:ntrain,::sub]\n",
    "x_test = x_data[-ntest:,::sub]\n",
    "y_test = y_data[-ntest:,::sub]\n",
    "\n",
    "x_train = x_train.unsqueeze(-1)\n",
    "x_test = x_test.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), \n",
    "                                            batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), \n",
    "                                            batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1/(N-1)\n",
    "\n",
    "coeffs_finite_difference_right = np.array([-1/(3*h), 3/(2*h), -3/h , 11/(6*h)])\n",
    "coeffs_finite_difference_right = coeffs_finite_difference_right.astype(np.float32)\n",
    "\n",
    "normalized_coeff_right = np.array([-2/11, 9/11, -18/11, 6*h/11]).astype(np.float32)\n",
    "normalized_coeff_right = torch.from_numpy(normalized_coeff_right).to(device)\n",
    "\n",
    "diff_fn_right = partial(compute_finite_diff, normalized_coeff_right, loc=-1)\n",
    "\n",
    "coeffs_finite_difference_left = np.array([1, -1])\n",
    "coeffs_finite_difference_left = coeffs_finite_difference_left.astype(np.float32)\n",
    "\n",
    "normalized_coeff_left = np.array([1, -1]).astype(np.float32)\n",
    "normalized_coeff_left = torch.from_numpy(normalized_coeff_left).to(device)\n",
    "diff_fn_left = partial(compute_finite_diff, normalized_coeff_left, loc=0)\n",
    "\n",
    "neumann_bdy_left = 0.0\n",
    "\n",
    "U = np.array([5])\n",
    "U = torch.from_numpy(U).to(device)\n",
    "\n",
    "t = np.array([0.5])\n",
    "t = torch.from_numpy(t).to(device)\n",
    "neumann_bdy_right = U*torch.sin(torch.pi*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_no = FNO1d(modes, width)\n",
    "model = BOON_FNO1d(width, \n",
    "                    base_no,\n",
    "                    bdy_type='neumann').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, \n",
    "                    bdy_left={'val':neumann_bdy_left, 'diff_fn':diff_fn_left},\n",
    "                    bdy_right={'val':neumann_bdy_right, 'diff_fn':diff_fn_right},\n",
    "                   )\n",
    "\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward() # use the l2 relative loss\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += l2.item()\n",
    "        \n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x, \n",
    "                        bdy_left={'val':neumann_bdy_left, 'diff_fn':diff_fn_left},\n",
    "                        bdy_right={'val':neumann_bdy_right, 'diff_fn':diff_fn_right},\n",
    "                       )\n",
    "\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_l2, test_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#  configurations\n",
    "################################################################\n",
    "ntrain = 500\n",
    "ntest = 100\n",
    "\n",
    "sub = 2**6 #subsampling rate\n",
    "h = 2**13 // sub #total grid size divided by the subsampling rate\n",
    "\n",
    "s = h\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 500\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 16\n",
    "width = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# read data\n",
    "################################################################\n",
    "# LOAD YOUR DATA HERE consists of pairs (a,u) with randomly generated initial conditions or PDE parameters a\n",
    "# and solution u\n",
    "rw_ = loadmat('Data/1D/Burgers Periodic/burgers_data_R10.mat')\n",
    "\n",
    "x_data = rw_['a'].astype(np.float32) # shape (num_random_simulations, number_grid_points)\n",
    "y_data = rw_['u'].astype(np.float32) # shape (num_random_simulations, number_grid_points)\n",
    "\n",
    "x_data = torch.from_numpy(x_data)\n",
    "y_data = torch.from_numpy(y_data)\n",
    "\n",
    "x_train = x_data[:ntrain,::sub]\n",
    "y_train = y_data[:ntrain,::sub]\n",
    "x_test = x_data[-ntest:,::sub]\n",
    "y_test = y_data[-ntest:,::sub]\n",
    "\n",
    "# strictly put periodic bdy condition\n",
    "x_train[:, -1] = x_train[:, 0]\n",
    "y_train[:, -1] = y_train[:, 0]\n",
    "x_test[:, -1] = x_test[:, 0]\n",
    "y_test[:, -1] = y_test[:, 0]\n",
    "\n",
    "x_train = x_train.unsqueeze(-1)\n",
    "x_test = x_test.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), \n",
    "                                            batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), \n",
    "                                            batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_no = FNO1d(modes, width)\n",
    "model = BOON_FNO1d(width, \n",
    "                    base_no,\n",
    "                    bdy_type='periodic').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward() # use the l2 relative loss\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += l2.item()\n",
    "        \n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    test_l2_near_bdy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_l2, test_l2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
